{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "# 数据读取\n",
    "import csv\n",
    "\n",
    "# 读取filename里面的数据\n",
    "def readFromFile(filename):\n",
    "    dataLines = []\n",
    "    with open(filename, newline='',encoding='utf-8') as f:\n",
    "#         remove the first line\n",
    "#         去除第一行\n",
    "        f.readline()\n",
    "        rows = csv.reader(f)\n",
    "        dataLines = list(rows)\n",
    "#         correct the label into standard form\n",
    "#         将字符型label转换为整数型label，并且补全将‘’补成0\n",
    "        for dataLine in dataLines:\n",
    "            if dataLine[0] == '0.0' or dataLine[0] == '':\n",
    "                dataLine[0] = 0\n",
    "            elif dataLine[0] == '1.0':\n",
    "                dataLine[0] = 1\n",
    "            \n",
    "            if dataLine[1] == '0.0' or dataLine[1] == '':\n",
    "                dataLine[1] = 0\n",
    "            elif dataLine[1] == '1.0':\n",
    "                dataLine[1] = 1\n",
    "    return dataLines\n",
    "\n",
    "filenames = ['data/part1.csv', 'data/part2.csv', 'data/part4.csv']\n",
    "dataLines = []\n",
    "for filename in filenames:\n",
    "    dataLines_ = readFromFile(filename)\n",
    "    dataLines += dataLines_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, '多次购买，经济实惠，尺寸合适']\n"
     ]
    }
   ],
   "source": [
    "# 查看最后一行数据\n",
    "print(dataLines[599])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment data preprocessing\n",
    "# 评论数据的预处理\n",
    "## 0. shuffle data\n",
    "## 0. 打乱数据顺序（需要注意由于数据打乱了，每次执行的结果都会不同）\n",
    "from random import shuffle\n",
    "shuffle(dataLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572\n"
     ]
    }
   ],
   "source": [
    "## 1. remove default comment\n",
    "## 1. 去除默认评论\n",
    "dataLines1 = [line for line in dataLines if line[2] != '此用户没有填写评论!']\n",
    "print(len(dataLines1))      # 查看剩余数据量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, '给了好评对不起自己收到的东西不给好评对不起下图销售人员保持沉默不作评论']\n"
     ]
    }
   ],
   "source": [
    "## 2. remove noise\n",
    "## 2. 移除噪声符号（可以修改，见文件word2vec/utils.py）\n",
    "## [参考](https://blog.csdn.net/mach_learn/article/details/41744487)\n",
    "import re\n",
    "from word2vec.utils import remove_noise\n",
    "\n",
    "dataLines2 = [[line[0], line[1], remove_noise(line[2])] for line in dataLines1]\n",
    "print(dataLines2[0])        # 随机查看一条数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. text segmentation\n",
    "## 3. 使用jieba分词\n",
    "import jieba\n",
    "\n",
    "def segmentation(text):\n",
    "    return jieba.cut(text)\n",
    "\n",
    "dataLines3 = [[line[0], line[1], segmentation(line[2])] for line in dataLines2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.598 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "## 4. remove stop words\n",
    "## 4. 移除停用词\n",
    "\n",
    "# 加载停用词\n",
    "def loadStopWords(filename):\n",
    "    stopwords = [line.strip() for line in \\\n",
    "                 open(filename, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "stopWordFilename = 'stop_words'\n",
    "stopWords = loadStopWords(stopWordFilename)\n",
    "dataLines4 = [[line[0], line[1], [word for word in line[2] if word not in stopWords]]\n",
    "             for line in dataLines3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, array([-0.5696369 ,  1.434681  , -1.3457062 , -1.0737123 ,  1.7944949 ,\n",
       "        -1.8746401 , -1.7441665 , -0.33646914, -1.3398262 , -0.613251  ,\n",
       "         3.7658167 , -0.81488925, -2.2925906 ,  3.2544887 ,  0.47307578,\n",
       "         2.6945121 , -0.25653872,  1.683943  ,  2.5718057 ,  3.3660645 ,\n",
       "        -2.7731285 ,  0.76614094,  0.29850632,  1.1424104 , -1.0080081 ,\n",
       "         1.1021123 , -0.8836053 ,  2.5620518 , -1.0686977 ,  2.7273965 ,\n",
       "        -2.1284513 , -1.0426029 , -0.11974853, -5.3148174 ,  3.2486863 ,\n",
       "        -1.5224168 ,  0.2926951 ,  0.46637464,  1.9785173 ,  0.98617196,\n",
       "        -3.0494134 , -0.34304577, -0.7633401 ,  1.0476135 , -0.3061484 ,\n",
       "         2.9846144 ,  0.78348136,  3.5827913 , -0.6293336 ,  0.9463711 ,\n",
       "        -0.17951652, -0.41948265,  1.7393503 , -0.47981304, -1.4905112 ,\n",
       "         1.8823681 , -0.39938334,  0.5702089 , -0.76978004, -1.8762641 ,\n",
       "         1.9003918 , -0.8907394 , -2.0959423 , -2.5957978 , -0.11157587,\n",
       "         0.23382859,  0.5976219 ,  2.2379594 , -0.36982894,  2.1283832 ,\n",
       "        -2.868552  ,  1.6984372 , -0.7803545 , -1.8846076 ,  0.75229186,\n",
       "        -0.7773911 ,  0.43046135, -1.0080495 ,  1.5529392 ,  1.2248441 ,\n",
       "        -1.7718275 , -1.9610527 , -1.7018968 ,  0.10403031, -2.7664573 ,\n",
       "        -1.0752254 ,  0.18761715,  1.7152467 ,  2.367524  ,  0.84622884,\n",
       "         0.5625388 , -1.0981265 , -3.5273156 ,  0.7809652 ,  0.22071452,\n",
       "         1.4598559 , -2.1972222 ,  3.0232527 , -1.4372525 , -1.0952928 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 5. word Embedding, the word2Vec training see folder word2vec\n",
    "## 5. 词向量嵌入，这里加载训练好的word2vec模型，训练过程见文件夹word2vec\n",
    "## Currently the corpus is not cleaned yet.\n",
    "## 现在训练word2vec模型的语料预处理同前面一样，调用remove_noise()和结巴分词\n",
    "import gensim\n",
    "\n",
    "# 加载训练好的模型\n",
    "model = gensim.models.Word2Vec.load('word2vec/w2v.model')\n",
    "\n",
    "# 将文本转换为词向量\n",
    "dataLines5 = []\n",
    "for line in dataLines4:\n",
    "    temp = []\n",
    "    temp = [model.wv[word] for word in line[2] if word in list(model.wv.vocab)]\n",
    "    if len(temp) == 0:\n",
    "        temp = [0 for i in range(100)]\n",
    "    else:\n",
    "        temp = sum(temp)\n",
    "    dataLines5.append([line[0], line[1], temp])\n",
    "dataLines5[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "# logistic回归\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# 将dataLines5的数据，label分开\n",
    "X_all = [line[2] for line in dataLines5]\n",
    "Y1_all = [line[0] for line in dataLines5]\n",
    "Y2_all = [line[1] for line in dataLines5]\n",
    "\n",
    "# 划分数据，前500条为训练集，后72条为测试集\n",
    "X_train = X_all[0:500]\n",
    "Y1_train = Y1_all[0:500]\n",
    "Y2_train = Y2_all[0:500]\n",
    "\n",
    "X_test = X_all[500:]\n",
    "Y1_test = Y1_all[500:]\n",
    "Y2_test = Y2_all[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9861111111111112"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train, Y1_train)\n",
    "clf.score(X_test, Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【因为本仙女很懒，不想每个产品都写好评，所以特地模仿好友写下这个模板，但是这个产品无论是质量还是外形都是本仙女喜欢的类型，如果不喜欢，仙女收到东西会很生气，然后这个模板就会成为仙女喋喋不休的休书，自然不可能撒下这个好评，给各位淘友一个参考，本产品还是极好的。 &mdash;&mdash;来自一位慵懒的只爱购物不爱写评语却想换积分的仙女！ 好吧，说真的，很好，喜欢。】\n",
      "\n",
      "宝贝已经收到了，真的是物有所值非常的满意。卖家的服务态度很好发货速度也很快，包裹的严严实实没有任何破损。快递小哥送货速度快，总体来说是一次愉快的购物呀，下次有需要还会再来买买买！与卖家描述的完全一致，非常满意,真的很喜欢，完全超出期望值，发货速度非常快今天收到快递，首先我第一次体验到神速的快递，昨天晚上买的，今天早上到了，其次看见我的商品，我觉得物美价廉非常的nice，天猫超市永远是正品，值得信赖，所以我的配图是爱心，因为我觉得很好很棒，很值得去再回购\n",
      "\n",
      "宝宝们！！！半,价入手滴！公～总～号 ：【真满意】再买，便宜了一半！！超级好！！！东西很好，价美物廉，质量杠杠滴，试穿了一下，舒适，于是就又买了一件，大小合适，样式也蛮喜欢的。身高170体重75公斤这个码很合适，颜色好看。衣服上身很好看，尺寸刚好，觉得好看，才买的，客服推荐的尺码穿上也特别的合适，我比较喜欢简单大方的衣服，上身效果也不错回复也很快，我问了不少问题，物流也比较快，衣服的面料比较柔软穿上很舒服，衣服面料好，物流也挺快的，也要用心敷衍吧，取到快递，客服服务态度好，衣服料子很好，\n",
      "\n",
      "宝宝们！！半，价买滴哟！公?总，号搜：【太实惠】再去买，超级划算！！！！排在最上面的那个才是哦！！收到衣服，就迫不及待的打开看了。第一次在米兔家买衣服，真心好呀，质量款式都好，也很厚实！试穿也好合身哦！很适合我的风格！ 这个颜色真是如描述超柔和的！而且很提肤色哦！这是目前买到的最满意的一件哟！喜欢！喜欢！快点冷起来吧！ 宝贝非常漂亮 和描述的一样 做工精致 款式漂亮 卖家服务非常好 耐心细致 包装非常讲究 不愧是品牌呀 还会在来的 物流也很给力 谢谢了 好评\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print data predict as template comment\n",
    "# 打印被分类为模板的评论\n",
    "Y1_predict = clf.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    if Y1_predict[i] == 1:\n",
    "        print(dataLines1[i+500][2])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "宝贝已经收到了，真的是物有所值非常的满意。卖家的服务态度很好发货速度也很快，包裹的严严实实没有任何破损。快递小哥送货速度快，总体来说是一次愉快的购物呀，下次有需要还会再来买买买！与卖家描述的完全一致，非常满意,真的很喜欢，完全超出期望值，发货速度非常快今天收到快递，首先我第一次体验到神速的快递，昨天晚上买的，今天早上到了，其次看见我的商品，我觉得物美价廉非常的nice，天猫超市永远是正品，值得信赖，所以我的配图是爱心，因为我觉得很好很棒，很值得去再回购\n",
      "True label 0\n",
      "Predict label 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the conflict data in test set\n",
    "# 打印模板评论分类错误的测试数据，便于分析\n",
    "\n",
    "def print_error_data(X_t, Y_t, Y_predict):\n",
    "    for i in range(len(X_t)):\n",
    "        if (Y_predict[i] != Y_t[i]):\n",
    "            print(dataLines1[i+500][2])\n",
    "            print(\"True label %d\" % Y_t[i])\n",
    "            print(\"Predict label %d\" % Y_predict[i])\n",
    "            print()\n",
    "            \n",
    "print_error_data(X_test, Y1_test, Y1_predict)\n",
    "# 可以看到，这里虽然标注为0，但是如果是我，我会标注为1（再次执行可能结果不同）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9027777777777778"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train, Y2_train)\n",
    "clf2.score(X_test, Y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【因为本仙女很懒，不想每个产品都写好评，所以特地模仿好友写下这个模板，但是这个产品无论是质量还是外形都是本仙女喜欢的类型，如果不喜欢，仙女收到东西会很生气，然后这个模板就会成为仙女喋喋不休的休书，自然不可能撒下这个好评，给各位淘友一个参考，本产品还是极好的。 &mdash;&mdash;来自一位慵懒的只爱购物不爱写评语却想换积分的仙女！ 好吧，说真的，很好，喜欢。】\n",
      "True label 0\n",
      "Predict label 1\n",
      "\n",
      "买回来的颜色跟展示图片的都不一样\n",
      "True label 0\n",
      "Predict label 1\n",
      "\n",
      "衣服好\n",
      "True label 1\n",
      "Predict label 0\n",
      "\n",
      "呱呱呱呱呱呱嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎嘎非常好，里面还有加绒。  哈哈哈哈哈嘎嘎嘎嘎\n",
      "True label 1\n",
      "Predict label 0\n",
      "\n",
      "宝宝们！！半，价买滴哟！公?总，号搜：【太实惠】再去买，超级划算！！！！排在最上面的那个才是哦！！收到衣服，就迫不及待的打开看了。第一次在米兔家买衣服，真心好呀，质量款式都好，也很厚实！试穿也好合身哦！很适合我的风格！ 这个颜色真是如描述超柔和的！而且很提肤色哦！这是目前买到的最满意的一件哟！喜欢！喜欢！快点冷起来吧！ 宝贝非常漂亮 和描述的一样 做工精致 款式漂亮 卖家服务非常好 耐心细致 包装非常讲究 不愧是品牌呀 还会在来的 物流也很给力 谢谢了 好评\n",
      "True label 0\n",
      "Predict label 1\n",
      "\n",
      "挺好看的舒服实费和团队采访了107个家庭、翻遍近几十年美国社会的各种统计资料后，帕特南得出了一个残酷的结论：在美国，阶层流动几近停顿，穷人再努力，也是出头无望。  情形有多严重呢？我们可以从一个侧面感受下\n",
      "True label 1\n",
      "Predict label 0\n",
      "\n",
      "跟图片一样，还不错，这个价位买到一件不错的衣服\n",
      "True label 0\n",
      "Predict label 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the conflict data in test set\n",
    "# 打印水评分类错误的测试数据，便于分析\n",
    "\n",
    "print_error_data(X_test, Y2_test, Y2_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# check how many comment in test set appeared in training set\n",
    "seen_count = 0\n",
    "for data_test in X_test:\n",
    "    for data_train in X_train:\n",
    "        if set(data_train) == set(data_test):\n",
    "            seen_count += 1\n",
    "            break\n",
    "print(seen_count)    \n",
    "# 可以看到出现在训练集的测试集数据只有1条（每次执行结果不同，重新执行会改变）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以调用其他模型训练 or 可以使用评估方法对实验结果进行评估\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
