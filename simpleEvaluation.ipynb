{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.763 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from readData import readTaobaoData\n",
    "import numpy as np\n",
    "\n",
    "dataLines, _ = readTaobaoData()\n",
    "\n",
    "# 将dataLines的数据，label分开\n",
    "X_all = np.array([line[2] for line in dataLines])\n",
    "Y1_all = [line[0] for line in dataLines]\n",
    "Y2_all = [line[1] for line in dataLines]\n",
    "\n",
    "# 划分数据，前500条为训练集，后72条为测试集\n",
    "X_train = X_all[0:500]\n",
    "Y1_train = Y1_all[0:500]\n",
    "Y2_train = Y2_all[0:500]\n",
    "\n",
    "X_test = X_all[500:]\n",
    "Y1_test = Y1_all[500:]\n",
    "Y2_test = Y2_all[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y1_test==np.ones(len(Y1_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y2_all==np.ones(len(Y1_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def printScores(Y_true, Y_pred):\n",
    "    head_format = '{:10}{:10}{:10}{:10}'\n",
    "    num_format = '%-10.2f%-10.2f%-10.2f%-10.2f'\n",
    "    print(head_format.format('accuracy', 'precision', 'recall', 'f1 score'))\n",
    "    print(num_format % (accuracy_score(Y_true, Y_pred)*100, \n",
    "                        precision_score(Y_true, Y_pred)*100,\n",
    "                        recall_score(Y_true, Y_pred)*100, \n",
    "                        f1_score(Y_true, Y_pred)*100))\n",
    "    \n",
    "def evaluate(X_train, Y_train, X_test, Y_test, clfClass, para):\n",
    "    clf = clfClass(**para)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_clf = clf.predict(X_test)\n",
    "    printScores(Y_test, Y_clf)\n",
    "    \n",
    "def gridSearchEvaluate(X_train, Y_train, X_test, Y_test,\n",
    "                       clfClass, gridPara, searchPara):\n",
    "    grid = GridSearchCV(clfClass(), searchPara, **gridPara)\n",
    "    grid.fit(np.concatenate((X_test, X_train)), np.concatenate((Y_test, Y_train)))\n",
    "    print('The best params is ', grid.best_params_, \n",
    "          '\\nWith scores %.2f%%' % (grid.best_score_*100))\n",
    "    evaluate(X_train, Y_train, X_test, Y_test, clfClass, grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchAccuracy = {'cv': 5, 'scoring': 'accuracy', 'n_jobs': -1}\n",
    "gridSearchPrecision = {'cv': 5, 'scoring': 'precision', 'n_jobs': -1}\n",
    "\n",
    "def gridSearchEvaluateWrapper(clfClass, gridPara, searchPara1, searchPara2):\n",
    "    gridSearchEvaluate(X_train, Y1_train, X_test, Y1_test, \n",
    "                       clfClass, gridPara, searchPara1)\n",
    "    print()\n",
    "    gridSearchEvaluate(X_train, Y2_train, X_test, Y2_test, \n",
    "                       clfClass, gridPara, searchPara2)\n",
    "    \n",
    "def scoringWrapper(clfClass, searchPara1, searchPara2):\n",
    "    print(\"Using scoring: accuracy\")\n",
    "    gridSearchEvaluateWrapper(clfClass, gridSearchAccuracy, searchPara1, searchPara2)\n",
    "    print()\n",
    "    print(\"Using scoring: precision\")\n",
    "    gridSearchEvaluateWrapper(clfClass, gridSearchPrecision, searchPara1, searchPara2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scoring: accuracy\n",
      "The best params is  {'n_neighbors': 6, 'weights': 'distance'} \n",
      "With scores 93.79%\n",
      "accuracy  precision recall    f1 score  \n",
      "93.75     87.50     63.64     73.68     \n",
      "\n",
      "The best params is  {'n_neighbors': 16, 'weights': 'distance'} \n",
      "With scores 83.79%\n",
      "accuracy  precision recall    f1 score  \n",
      "88.12     90.00     51.43     65.45     \n",
      "\n",
      "Using scoring: precision\n",
      "The best params is  {'n_neighbors': 16, 'weights': 'distance'} \n",
      "With scores 87.13%\n",
      "accuracy  precision recall    f1 score  \n",
      "95.00     93.75     68.18     78.95     \n",
      "\n",
      "The best params is  {'n_neighbors': 24, 'weights': 'uniform'} \n",
      "With scores 86.94%\n",
      "accuracy  precision recall    f1 score  \n",
      "86.88     88.89     45.71     60.38     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_list=[i+1  for i in range(40)]\n",
    "knn_para = dict(n_neighbors=k_list, weights=['uniform','distance'])\n",
    "scoringWrapper(KNeighborsClassifier, knn_para, knn_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scoring: accuracy\n",
      "The best params is  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'} \n",
      "With scores 94.24%\n",
      "accuracy  precision recall    f1 score  \n",
      "95.62     94.12     72.73     82.05     \n",
      "\n",
      "The best params is  {'C': 1, 'kernel': 'linear'} \n",
      "With scores 84.55%\n",
      "accuracy  precision recall    f1 score  \n",
      "87.50     80.00     57.14     66.67     \n",
      "\n",
      "Using scoring: precision\n",
      "The best params is  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'} \n",
      "With scores 85.99%\n",
      "accuracy  precision recall    f1 score  \n",
      "95.62     94.12     72.73     82.05     \n",
      "\n",
      "The best params is  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'} \n",
      "With scores 86.26%\n",
      "accuracy  precision recall    f1 score  \n",
      "86.88     88.89     45.71     60.38     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_para = [{'kernel': ['rbf'], 'gamma': [1e-3,1e-4], 'C': [1,10,100]},\n",
    "            {'kernel': ['linear'], 'C': [1,10,100]}]\n",
    "scoringWrapper(SVC, svm_para, svm_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  precision recall    f1 score  \n",
      "92.50     72.73     72.73     72.73     \n",
      "accuracy  precision recall    f1 score  \n",
      "83.75     69.57     45.71     55.17     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb1 = GaussianNB()\n",
    "gnb1.fit(X_train,Y1_train)\n",
    "Y1_bayes = gnb1.predict(X_test)\n",
    "printScores(Y1_test, Y1_bayes)\n",
    "\n",
    "gnb2 = GaussianNB()\n",
    "gnb2.fit(X_train,Y2_train)\n",
    "Y2_bayes = gnb2.predict(X_test)\n",
    "printScores(Y2_test, Y2_bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scoring: accuracy\n",
      "The best params is  {'max_iter': 100000, 'penalty': 'l1'} \n",
      "With scores 93.48%\n",
      "accuracy  precision recall    f1 score  \n",
      "93.75     80.00     72.73     76.19     \n",
      "\n",
      "The best params is  {'max_iter': 100000, 'penalty': 'l2', 'solver': 'liblinear'} \n",
      "With scores 83.94%\n",
      "accuracy  precision recall    f1 score  \n",
      "85.62     71.43     57.14     63.49     \n",
      "\n",
      "Using scoring: precision\n",
      "The best params is  {'max_iter': 100000, 'penalty': 'l1'} \n",
      "With scores 82.86%\n",
      "accuracy  precision recall    f1 score  \n",
      "93.75     80.00     72.73     76.19     \n",
      "\n",
      "The best params is  {'max_iter': 100000, 'penalty': 'l2', 'solver': 'liblinear'} \n",
      "With scores 78.19%\n",
      "accuracy  precision recall    f1 score  \n",
      "85.62     71.43     57.14     63.49     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag','saga']\n",
    "logistic_para = [{'solver': solvers, 'penalty': ['l2'], \"max_iter\": [int(1e5), int(1e4)]},\n",
    "                {'penalty': ['l1'], \"max_iter\": [int(1e5), int(1e4)]}]\n",
    "scoringWrapper(LogisticRegression, logistic_para, logistic_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scoring: accuracy\n",
      "The best params is  {'max_depth': 2, 'max_features': 19} \n",
      "With scores 93.79%\n",
      "accuracy  precision recall    f1 score  \n",
      "91.25     68.18     68.18     68.18     \n",
      "\n",
      "The best params is  {'max_depth': 1, 'max_features': 10} \n",
      "With scores 84.09%\n",
      "accuracy  precision recall    f1 score  \n",
      "85.62     80.00     45.71     58.18     \n",
      "\n",
      "Using scoring: precision\n",
      "The best params is  {'max_depth': 2, 'max_features': 26} \n",
      "With scores 84.86%\n",
      "accuracy  precision recall    f1 score  \n",
      "93.12     86.67     59.09     70.27     \n",
      "\n",
      "The best params is  {'max_depth': 2, 'max_features': 15} \n",
      "With scores 87.32%\n",
      "accuracy  precision recall    f1 score  \n",
      "83.12     83.33     28.57     42.55     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dTree_para = [{'max_features' :[i for i in range(10,30)], \n",
    "               'max_depth': [i for i in range(1,20)]}]\n",
    "scoringWrapper(DecisionTreeClassifier, dTree_para, dTree_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scoring: accuracy\n",
      "The best params is  {'n_estimators': 21} \n",
      "With scores 93.48%\n",
      "accuracy  precision recall    f1 score  \n",
      "91.88     73.68     63.64     68.29     \n",
      "\n",
      "The best params is  {'n_estimators': 53} \n",
      "With scores 84.55%\n",
      "accuracy  precision recall    f1 score  \n",
      "85.00     70.37     54.29     61.29     \n",
      "\n",
      "Using scoring: precision\n",
      "The best params is  {'n_estimators': 35} \n",
      "With scores 84.60%\n",
      "accuracy  precision recall    f1 score  \n",
      "95.00     93.75     68.18     78.95     \n",
      "\n",
      "The best params is  {'n_estimators': 1} \n",
      "With scores 86.14%\n",
      "accuracy  precision recall    f1 score  \n",
      "83.75     71.43     42.86     53.57     \n",
      "\n",
      "Using scoring: accuracy\n",
      "The best params is  {'n_estimators': 37} \n",
      "With scores 93.79%\n",
      "accuracy  precision recall    f1 score  \n",
      "92.50     77.78     63.64     70.00     \n",
      "\n",
      "The best params is  {'n_estimators': 81} \n",
      "With scores 85.30%\n",
      "accuracy  precision recall    f1 score  \n",
      "84.38     64.71     62.86     63.77     \n",
      "\n",
      "Using scoring: precision\n",
      "The best params is  {'n_estimators': 9} \n",
      "With scores 84.15%\n",
      "accuracy  precision recall    f1 score  \n",
      "92.50     77.78     63.64     70.00     \n",
      "\n",
      "The best params is  {'n_estimators': 27} \n",
      "With scores 76.81%\n",
      "accuracy  precision recall    f1 score  \n",
      "82.50     61.29     54.29     57.58     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Due to bad design, we need two seperate wrapper and run scoringWrapper two times.\n",
    "def adaBoostWrapper1(n_estimators=50):\n",
    "    return AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, max_features=26), \n",
    "                              algorithm=\"SAMME\", n_estimators=n_estimators)\n",
    "\n",
    "def adaBoostWrapper2(n_estimators=50):\n",
    "    return AdaBoostClassifier(DecisionTreeClassifier(max_depth=2, max_features=15), \n",
    "                              algorithm=\"SAMME\", n_estimators=n_estimators)\n",
    "\n",
    "ada_para = [{'n_estimators': [i for i in range(1,100,2)]}]\n",
    "scoringWrapper(adaBoostWrapper1, ada_para, ada_para)\n",
    "print()\n",
    "scoringWrapper(adaBoostWrapper2, ada_para, ada_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  precision recall    f1 score  \n",
      "91.88     71.43     68.18     69.77     \n",
      "accuracy  precision recall    f1 score  \n",
      "86.25     70.97     62.86     66.67     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gdb1 = GradientBoostingClassifier()\n",
    "gdb1.fit(X_train, Y1_train)\n",
    "Y1_gdb = gdb1.predict(X_test)\n",
    "printScores(Y1_test, Y1_gdb)\n",
    "\n",
    "gdb2 = GradientBoostingClassifier()\n",
    "gdb2.fit(X_train, Y2_train)\n",
    "Y2_gdb = gdb2.predict(X_test)\n",
    "printScores(Y2_test, Y2_gdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scoring: accuracy\n",
      "The best params is  {'max_depth': 16, 'max_features': 1, 'n_estimators': 155} \n",
      "With scores 94.09%\n",
      "accuracy  precision recall    f1 score  \n",
      "91.88     71.43     68.18     69.77     \n",
      "\n",
      "The best params is  {'max_depth': 11, 'max_features': 17, 'n_estimators': 10} \n",
      "With scores 85.76%\n",
      "accuracy  precision recall    f1 score  \n",
      "85.00     72.00     51.43     60.00     \n",
      "\n",
      "Using scoring: precision\n",
      "The best params is  {'max_depth': 1, 'max_features': 1, 'n_estimators': 155} \n",
      "With scores 87.64%\n",
      "accuracy  precision recall    f1 score  \n",
      "93.12     92.31     54.55     68.57     \n",
      "\n",
      "The best params is  {'max_depth': 1, 'max_features': 1, 'n_estimators': 155} \n",
      "With scores 87.92%\n",
      "accuracy  precision recall    f1 score  \n",
      "85.00     82.35     40.00     53.85     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_para = [{'max_features': [i for i in range(1,32,4)], \n",
    "            'max_depth': [i for i in range(1,20,5)], \n",
    "            'n_estimators': [10,155]}]\n",
    "scoringWrapper(RandomForestClassifier, rf_para, rf_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
